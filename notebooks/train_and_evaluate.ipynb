{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-16T11:09:16.805011Z",
     "start_time": "2025-09-16T11:09:04.768525Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Für XGBoost und LightGBM\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Daten laden und Feature-Definition wie gehabt\n",
    "df = pd.read_csv('../data/processed/test.csv')\n",
    "group_col = 'c_serial_number'\n",
    "time_col = 'msg_timestamp'\n",
    "target_col = 'failure_after_7_days'\n",
    "excluded_cols = [group_col, time_col, target_col, 'c_van17', 'first_valid_time','time_diff_days']\n",
    "feature_cols = [\n",
    "    c for c in df.select_dtypes(include=[np.number]).columns\n",
    "    if c not in excluded_cols\n",
    "]\n",
    "\n",
    "# Zeitbasierter Split pro Gruppe (wie oben)\n",
    "df_sorted = df.sort_values([group_col, time_col]).copy()\n",
    "train_frac = 0.8\n",
    "train_indices, test_indices = [], []\n",
    "\n",
    "for g, grp in df_sorted.groupby(group_col):\n",
    "    n = len(grp)\n",
    "    k_train = max(1, int(n * train_frac))\n",
    "    train_indices.extend(grp.index[:k_train].tolist())\n",
    "    test_indices.extend(grp.index[k_train:].tolist())\n",
    "\n",
    "df_train = df_sorted.loc[train_indices]\n",
    "df_test = df_sorted.loc[test_indices]\n",
    "\n",
    "X_train = df_train[feature_cols]\n",
    "y_train = df_train[target_col]\n",
    "X_test = df_test[feature_cols]\n",
    "y_test = df_test[target_col]\n",
    "\n",
    "# Balancing: Oversampling der True-Klasse im Training\n",
    "from sklearn.utils import resample\n",
    "\n",
    "train_df = pd.concat([X_train, y_train.rename(target_col)], axis=1)\n",
    "df_false = train_df[train_df[target_col] == 0]\n",
    "df_true = train_df[train_df[target_col] == 1]\n",
    "n_target = max(len(df_false), len(df_true))\n",
    "df_true_oversampled = resample(df_true, replace=True, n_samples=n_target, random_state=42)\n",
    "train_balanced = pd.concat([df_false, df_true_oversampled])\n",
    "X_train_bal = train_balanced[feature_cols]\n",
    "y_train_bal = train_balanced[target_col]\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Q548239\\AppData\\Local\\Temp\\ipykernel_16252\\4168846776.py:13: DtypeWarning: Columns (71,72) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/processed/test.csv')\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T11:09:21.607082Z",
     "start_time": "2025-09-16T11:09:16.836980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Zeitbasierten Split pro Gruppe (wie oben erarbeitet)\n",
    "df_sorted = df.sort_values([group_col, time_col]).copy()\n",
    "train_frac = 0.8  # 80% Training, 20% Test\n",
    "\n",
    "train_indices = []\n",
    "test_indices = []\n",
    "\n",
    "for g, grp in df_sorted.groupby(group_col):\n",
    "    n = len(grp)\n",
    "    if n == 0:\n",
    "        continue\n",
    "    k_train = max(1, int(n * train_frac))\n",
    "    train_idx_grp = grp.index[:k_train]\n",
    "    test_idx_grp = grp.index[k_train:]\n",
    "    train_indices.extend(train_idx_grp.tolist())\n",
    "    test_indices.extend(test_idx_grp.tolist())\n",
    "\n",
    "df_train = df_sorted.loc[train_indices]\n",
    "df_test = df_sorted.loc[test_indices]\n",
    "\n",
    "X_train = df_train[feature_cols]\n",
    "y_train = df_train[target_col]\n",
    "X_test = df_test[feature_cols]\n",
    "y_test = df_test[target_col]"
   ],
   "id": "66cdedabf00411fe",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T11:09:23.457427Z",
     "start_time": "2025-09-16T11:09:21.777221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Balancing des Trainingsdatensatzes (Oversampling der True-Klasse)\n",
    "from sklearn.utils import resample\n",
    "\n",
    "train_df = pd.concat([X_train, y_train.rename(target_col)], axis=1)\n",
    "df_false = train_df[train_df[target_col] == 0]\n",
    "df_true = train_df[train_df[target_col] == 1]\n",
    "n_target = max(len(df_false), len(df_true))\n",
    "df_true_oversampled = resample(df_true, replace=True, n_samples=n_target, random_state=42)\n",
    "train_balanced = pd.concat([df_false, df_true_oversampled])\n",
    "X_train_bal = train_balanced[feature_cols]\n",
    "y_train_bal = train_balanced[target_col]"
   ],
   "id": "12c30dd20234e402",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T11:22:26.085005Z",
     "start_time": "2025-09-16T11:09:23.612391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "models = {\n",
    "    'RandomForest': (\n",
    "        RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "        {\n",
    "            'n_estimators': [200],\n",
    "            'max_depth': [15],\n",
    "            'class_weight': ['balanced']\n",
    "        }\n",
    "    ),\n",
    "    'XGBoost': (\n",
    "        XGBClassifier(random_state=42, n_jobs=-1, use_label_encoder=False, eval_metric='logloss'),\n",
    "        {\n",
    "            'n_estimators': [200],\n",
    "            'max_depth': [15],\n",
    "            'scale_pos_weight': [1, len(df_false)/len(df_true)]  # Handling Imbalance\n",
    "        }\n",
    "    ),\n",
    "    'LightGBM': (\n",
    "        LGBMClassifier(random_state=42, n_jobs=-1),\n",
    "        {\n",
    "            'n_estimators': [200],\n",
    "            'max_depth': [15],\n",
    "            'class_weight': ['balanced']\n",
    "        }\n",
    "    ),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, (model, params) in models.items():\n",
    "    print(f\"\\nTrainiere & tune {name} ...\")\n",
    "    gs = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=params,\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=1,\n",
    "        cv=skf,\n",
    "        verbose=1\n",
    "    )\n",
    "    gs.fit(X_train_bal, y_train_bal)\n",
    "    best_model = gs.best_estimator_\n",
    "    print(f\"Best Score (AUC): {gs.best_score_:.4f}\")\n",
    "    print(f\"Best Params: {gs.best_params_}\")\n",
    "    results[name] = {\n",
    "        'model': best_model,\n",
    "        'cv_score': gs.best_score_,\n",
    "        'params': gs.best_params_\n",
    "    }\n"
   ],
   "id": "bd0cdb52a2fa46ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trainiere & tune RandomForest ...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Best Score (AUC): 0.9498\n",
      "Best Params: {'class_weight': 'balanced', 'max_depth': 15, 'n_estimators': 200}\n",
      "\n",
      "Trainiere & tune XGBoost ...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Q548239\\devbr\\prediction\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:16:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Q548239\\devbr\\prediction\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Q548239\\devbr\\prediction\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:17:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Q548239\\devbr\\prediction\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:18:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Q548239\\devbr\\prediction\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:19:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Q548239\\devbr\\prediction\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\Q548239\\devbr\\prediction\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:20:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score (AUC): 1.0000\n",
      "Best Params: {'max_depth': 15, 'n_estimators': 200, 'scale_pos_weight': 22.981502117227546}\n",
      "\n",
      "Trainiere & tune LightGBM ...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[LightGBM] [Info] Number of positive: 343727, number of negative: 343726\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 14138\n",
      "[LightGBM] [Info] Number of data points in the train set: 687453, number of used features: 110\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 343726, number of negative: 343727\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 14139\n",
      "[LightGBM] [Info] Number of data points in the train set: 687453, number of used features: 110\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 343727, number of negative: 343727\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.149047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14107\n",
      "[LightGBM] [Info] Number of data points in the train set: 687454, number of used features: 110\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 515590, number of negative: 515590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.123380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 14106\n",
      "[LightGBM] [Info] Number of data points in the train set: 1031180, number of used features: 110\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Best Score (AUC): 0.9250\n",
      "Best Params: {'class_weight': 'balanced', 'max_depth': 15, 'n_estimators': 200}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T11:22:29.269206Z",
     "start_time": "2025-09-16T11:22:26.324898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n--- Evaluation auf Testdaten ---\\n\")\n",
    "for name, res in results.items():\n",
    "    model = res['model']\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  ROC-AUC:    {auc:.4f}\")\n",
    "    print(f\"  F1-Score:   {f1:.4f}\")\n",
    "    print(f\"  Precision:  {prec:.4f}\")\n",
    "    print(f\"  Recall:     {rec:.4f}\\n\")\n",
    "    results[name].update({'auc': auc, 'f1': f1, 'precision': prec, 'recall': rec})\n"
   ],
   "id": "de3974edc7250b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation auf Testdaten ---\n",
      "\n",
      "RandomForest:\n",
      "  ROC-AUC:    0.6432\n",
      "  F1-Score:   0.3346\n",
      "  Precision:  0.6428\n",
      "  Recall:     0.2261\n",
      "\n",
      "XGBoost:\n",
      "  ROC-AUC:    0.6989\n",
      "  F1-Score:   0.3706\n",
      "  Precision:  0.9482\n",
      "  Recall:     0.2303\n",
      "\n",
      "LightGBM:\n",
      "  ROC-AUC:    0.6978\n",
      "  F1-Score:   0.4300\n",
      "  Precision:  0.7796\n",
      "  Recall:     0.2968\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T11:22:29.412392Z",
     "start_time": "2025-09-16T11:22:29.406268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Wähle das Modell mit dem höchsten ROC-AUC\n",
    "best_name = max(results, key=lambda x: results[x]['auc'])\n",
    "best_model = results[best_name]['model']\n",
    "print(f\"Bestes Modell: {best_name} mit ROC-AUC {results[best_name]['auc']:.4f}\")\n"
   ],
   "id": "c991ee93948e2a53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bestes Modell: XGBoost mit ROC-AUC 0.6989\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T11:38:25.077980Z",
     "start_time": "2025-09-16T11:29:25.325558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Auswahl Komponenten mit bestem Modell\n",
    "\n",
    "# Beispiel: new_logs = pd.read_csv('dein_neuer_logs_file.csv')\n",
    "# new_logs['predicted_failure_prob'] = best_model.predict_proba(new_logs[feature_cols])[:,1]\n",
    "\n",
    "# Hier als Beispiel X_test:\n",
    "new_logs = X_test.copy()\n",
    "new_logs['predicted_failure_prob'] = best_model.predict_proba(new_logs)[:,1]\n",
    "\n",
    "# Schwelle so wählen, dass der Mittelwert möglichst nahe an 0.10 liegt\n",
    "possible_thresholds = np.unique(new_logs['predicted_failure_prob'])\n",
    "best_diff = float('inf')\n",
    "best_thresh = None\n",
    "\n",
    "for thresh in possible_thresholds[::-1]:  # von hoch nach niedrig\n",
    "    subset = new_logs[new_logs['predicted_failure_prob'] >= thresh]\n",
    "    if len(subset) == 0:\n",
    "        continue\n",
    "    mean_prob = subset['predicted_failure_prob'].mean()\n",
    "    diff = abs(mean_prob - 0.10)\n",
    "    if diff < best_diff:\n",
    "        best_diff = diff\n",
    "        best_thresh = thresh\n",
    "        best_selected = subset\n",
    "\n",
    "    if diff <= 0.0025:\n",
    "        break\n",
    "\n",
    "selected = best_selected\n",
    "print(f\"Gewählte Schwelle: {best_thresh}\")\n",
    "print(f\"Durchschnittliche Wahrscheinlichkeit: {selected['predicted_failure_prob'].mean():.4f}\")\n",
    "print(f\"Anzahl ausgewählter Komponenten: {len(selected)}\")\n",
    "\n"
   ],
   "id": "8be3a5826f2e1b55",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 14\u001B[39m\n\u001B[32m     11\u001B[39m best_thresh = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m thresh \u001B[38;5;129;01min\u001B[39;00m possible_thresholds[::-\u001B[32m1\u001B[39m]:  \u001B[38;5;66;03m# von hoch nach niedrig\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m     subset = \u001B[43mnew_logs\u001B[49m\u001B[43m[\u001B[49m\u001B[43mnew_logs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mpredicted_failure_prob\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[43m>\u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mthresh\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m     15\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(subset) == \u001B[32m0\u001B[39m:\n\u001B[32m     16\u001B[39m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4098\u001B[39m, in \u001B[36mDataFrame.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   4096\u001B[39m \u001B[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001B[39;00m\n\u001B[32m   4097\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m com.is_bool_indexer(key):\n\u001B[32m-> \u001B[39m\u001B[32m4098\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_getitem_bool_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4100\u001B[39m \u001B[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001B[39;00m\n\u001B[32m   4101\u001B[39m \u001B[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001B[39;00m\n\u001B[32m   4102\u001B[39m is_single_key = \u001B[38;5;28misinstance\u001B[39m(key, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_list_like(key)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4160\u001B[39m, in \u001B[36mDataFrame._getitem_bool_array\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   4157\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.copy(deep=\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m   4159\u001B[39m indexer = key.nonzero()[\u001B[32m0\u001B[39m]\n\u001B[32m-> \u001B[39m\u001B[32m4160\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_take_with_is_copy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:4172\u001B[39m, in \u001B[36mNDFrame._take_with_is_copy\u001B[39m\u001B[34m(self, indices, axis)\u001B[39m\n\u001B[32m   4161\u001B[39m \u001B[38;5;129m@final\u001B[39m\n\u001B[32m   4162\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_take_with_is_copy\u001B[39m(\u001B[38;5;28mself\u001B[39m, indices, axis: Axis = \u001B[32m0\u001B[39m) -> Self:\n\u001B[32m   4163\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   4164\u001B[39m \u001B[33;03m    Internal version of the `take` method that sets the `_is_copy`\u001B[39;00m\n\u001B[32m   4165\u001B[39m \u001B[33;03m    attribute to keep track of the parent dataframe (using in indexing\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   4170\u001B[39m \u001B[33;03m    See the docstring of `take` for full explanation of the parameters.\u001B[39;00m\n\u001B[32m   4171\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m4172\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtake\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindices\u001B[49m\u001B[43m=\u001B[49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4173\u001B[39m     \u001B[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001B[39;00m\n\u001B[32m   4174\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.ndim == \u001B[32m2\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m result._get_axis(axis).equals(\u001B[38;5;28mself\u001B[39m._get_axis(axis)):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:4152\u001B[39m, in \u001B[36mNDFrame.take\u001B[39m\u001B[34m(self, indices, axis, **kwargs)\u001B[39m\n\u001B[32m   4147\u001B[39m     \u001B[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001B[39;00m\n\u001B[32m   4148\u001B[39m     indices = np.arange(\n\u001B[32m   4149\u001B[39m         indices.start, indices.stop, indices.step, dtype=np.intp\n\u001B[32m   4150\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m4152\u001B[39m new_data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_mgr\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtake\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4153\u001B[39m \u001B[43m    \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4154\u001B[39m \u001B[43m    \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_block_manager_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4155\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverify\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   4156\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4157\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._constructor_from_mgr(new_data, axes=new_data.axes).__finalize__(\n\u001B[32m   4158\u001B[39m     \u001B[38;5;28mself\u001B[39m, method=\u001B[33m\"\u001B[39m\u001B[33mtake\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   4159\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:894\u001B[39m, in \u001B[36mBaseBlockManager.take\u001B[39m\u001B[34m(self, indexer, axis, verify)\u001B[39m\n\u001B[32m    891\u001B[39m indexer = maybe_convert_indices(indexer, n, verify=verify)\n\u001B[32m    893\u001B[39m new_labels = \u001B[38;5;28mself\u001B[39m.axes[axis].take(indexer)\n\u001B[32m--> \u001B[39m\u001B[32m894\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mreindex_indexer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    895\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnew_axis\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnew_labels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    896\u001B[39m \u001B[43m    \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m=\u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    897\u001B[39m \u001B[43m    \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    898\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_dups\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    899\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    900\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:688\u001B[39m, in \u001B[36mBaseBlockManager.reindex_indexer\u001B[39m\u001B[34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001B[39m\n\u001B[32m    680\u001B[39m     new_blocks = \u001B[38;5;28mself\u001B[39m._slice_take_blocks_ax0(\n\u001B[32m    681\u001B[39m         indexer,\n\u001B[32m    682\u001B[39m         fill_value=fill_value,\n\u001B[32m    683\u001B[39m         only_slice=only_slice,\n\u001B[32m    684\u001B[39m         use_na_proxy=use_na_proxy,\n\u001B[32m    685\u001B[39m     )\n\u001B[32m    686\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    687\u001B[39m     new_blocks = [\n\u001B[32m--> \u001B[39m\u001B[32m688\u001B[39m         \u001B[43mblk\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtake_nd\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    689\u001B[39m \u001B[43m            \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    690\u001B[39m \u001B[43m            \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    691\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    692\u001B[39m \u001B[43m                \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mblk\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfill_value\u001B[49m\n\u001B[32m    693\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    694\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    695\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m blk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.blocks\n\u001B[32m    696\u001B[39m     ]\n\u001B[32m    698\u001B[39m new_axes = \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m.axes)\n\u001B[32m    699\u001B[39m new_axes[axis] = new_axis\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1373\u001B[39m, in \u001B[36mBlock.take_nd\u001B[39m\u001B[34m(self, indexer, axis, new_mgr_locs, fill_value)\u001B[39m\n\u001B[32m   1370\u001B[39m     allow_fill = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m   1372\u001B[39m \u001B[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1373\u001B[39m new_values = \u001B[43malgos\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtake_nd\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1374\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_fill\u001B[49m\u001B[43m=\u001B[49m\u001B[43mallow_fill\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfill_value\u001B[49m\n\u001B[32m   1375\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1377\u001B[39m \u001B[38;5;66;03m# Called from three places in managers, all of which satisfy\u001B[39;00m\n\u001B[32m   1378\u001B[39m \u001B[38;5;66;03m#  these assertions\u001B[39;00m\n\u001B[32m   1379\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, ExtensionBlock):\n\u001B[32m   1380\u001B[39m     \u001B[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001B[39;00m\n\u001B[32m   1381\u001B[39m     \u001B[38;5;66;03m#  algos.take_nd call above.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001B[39m, in \u001B[36mtake_nd\u001B[39m\u001B[34m(arr, indexer, axis, fill_value, allow_fill)\u001B[39m\n\u001B[32m    114\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m arr.take(indexer, fill_value=fill_value, allow_fill=allow_fill)\n\u001B[32m    116\u001B[39m arr = np.asarray(arr)\n\u001B[32m--> \u001B[39m\u001B[32m117\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_take_nd_ndarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_fill\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:162\u001B[39m, in \u001B[36m_take_nd_ndarray\u001B[39m\u001B[34m(arr, indexer, axis, fill_value, allow_fill)\u001B[39m\n\u001B[32m    157\u001B[39m     out = np.empty(out_shape, dtype=dtype)\n\u001B[32m    159\u001B[39m func = _get_take_nd_function(\n\u001B[32m    160\u001B[39m     arr.ndim, arr.dtype, out.dtype, axis=axis, mask_info=mask_info\n\u001B[32m    161\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m162\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    164\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m flip_order:\n\u001B[32m    165\u001B[39m     out = out.T\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
